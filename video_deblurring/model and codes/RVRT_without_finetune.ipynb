{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1oV2cyYWdmO",
        "outputId": "4c8fa1fd-1117-46d1-b89d-e8aad3149f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RVRT'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 48 (delta 4), reused 3 (delta 3), pack-reused 37 (from 1)\u001b[K\n",
            "Receiving objects: 100% (48/48), 2.87 MiB | 5.78 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n",
            "/content/RVRT\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,776 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,037 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,296 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,556 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,750 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,986 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,249 kB]\n",
            "Fetched 23.0 MB in 6s (3,907 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libgl1-mesa-glx is already the newest version (23.0.4-0ubuntu1~22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Collecting addict (from -r requirements.txt (line 1))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.11.0.86)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (11.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.32.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (0.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.21.0+cu124)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (1.0.15)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.8.1)\n",
            "Collecting ninja (from -r requirements.txt (line 14))\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 7)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 7)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 7)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 7)) (2025.4.26)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 8)) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 8)) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 8)) (2025.6.1)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 8)) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 8)) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->-r requirements.txt (line 10)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->-r requirements.txt (line 10)) (4.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->-r requirements.txt (line 10)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->-r requirements.txt (line 10)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.9.1->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.9.1->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.9.1->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9.1->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9.1->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9.1->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9.1->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9.1->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9.1->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->-r requirements.txt (line 10)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->-r requirements.txt (line 10)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->-r requirements.txt (line 10)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9.1->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->-r requirements.txt (line 10)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->-r requirements.txt (line 10)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9.1->-r requirements.txt (line 10)) (1.3.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm->-r requirements.txt (line 12)) (0.32.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm->-r requirements.txt (line 12)) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 12)) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 12)) (1.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.1->-r requirements.txt (line 10)) (3.0.2)\n",
            "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: addict, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed addict-2.4.0 ninja-1.11.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "python3: can't open file '/content/RVRT/setup.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Clone official RVRT repo\n",
        "!git clone https://github.com/JingyunLiang/RVRT.git\n",
        "%cd RVRT\n",
        "\n",
        "# Install dependencies and build the package\n",
        "!apt-get update && apt-get install -y libgl1-mesa-glx\n",
        "!pip install -r requirements.txt\n",
        "!pip install torch torchvision torchaudio\n",
        "!python setup.py develop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(dim, dim, 3, 1, 1, groups=dim)\n",
        "        self.norm = nn.GroupNorm(1, dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = self.conv(x)\n",
        "        attn = self.norm(attn)\n",
        "        attn = torch.sigmoid(attn)\n",
        "        return x * attn\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(dim, dim // 4, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(dim // 4, dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.fc(x)\n",
        "\n",
        "class ConvLSTMCell(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, kernel_size=3):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        padding = kernel_size // 2\n",
        "\n",
        "        # Combined convolution for all gates\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=input_dim + hidden_dim,\n",
        "            out_channels=4 * hidden_dim,  # i, f, o, g gates\n",
        "            kernel_size=kernel_size,\n",
        "            padding=padding,\n",
        "            bias=True\n",
        "        )\n",
        "\n",
        "    def forward(self, input_tensor, cur_state):\n",
        "        h_cur, c_cur = cur_state\n",
        "\n",
        "        # Concatenate input and hidden state\n",
        "        combined = torch.cat([input_tensor, h_cur], dim=1)\n",
        "\n",
        "        # Apply convolution\n",
        "        combined_conv = self.conv(combined)\n",
        "\n",
        "        # Split into gates\n",
        "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
        "\n",
        "        # Apply activations\n",
        "        i = torch.sigmoid(cc_i)\n",
        "        f = torch.sigmoid(cc_f)\n",
        "        o = torch.sigmoid(cc_o)\n",
        "        g = torch.tanh(cc_g)\n",
        "\n",
        "        # Update cell state\n",
        "        c_next = f * c_cur + i * g\n",
        "        h_next = o * torch.tanh(c_next)\n",
        "\n",
        "        return h_next, c_next\n",
        "\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=64):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 32, 3, 1, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
        "        self.conv3 = nn.Conv2d(64, out_channels, 3, 1, 1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        return x\n",
        "\n",
        "class FeatureRefinement(nn.Module):\n",
        "    def __init__(self, channels=64):\n",
        "        super().__init__()\n",
        "        self.spatial_attn = SpatialAttention(channels)\n",
        "        self.channel_attn = ChannelAttention(channels)\n",
        "        self.conv_refine = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, 3, 1, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channels, channels, 3, 1, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = self.spatial_attn(x)\n",
        "        x = self.channel_attn(x)\n",
        "        x = self.conv_refine(x)\n",
        "        return x + residual\n",
        "\n",
        "class Reconstructor(nn.Module):\n",
        "    def __init__(self, in_channels=64, out_channels=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 32, 3, 1, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 16, 3, 1, 1)\n",
        "        self.conv3 = nn.Conv2d(16, out_channels, 3, 1, 1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = torch.tanh(self.conv3(x))  # Output in [-1, 1]\n",
        "        return x\n",
        "\n",
        "class RVRT(nn.Module):\n",
        "    def __init__(self, channels=64):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "\n",
        "        # Feature extraction\n",
        "        self.feature_extractor = FeatureExtractor(3, channels)\n",
        "\n",
        "        # ConvLSTM for temporal modeling\n",
        "        self.conv_lstm = ConvLSTMCell(channels, channels)\n",
        "\n",
        "        # Feature refinement\n",
        "        self.feature_refinement = FeatureRefinement(channels)\n",
        "\n",
        "        # Reconstruction\n",
        "        self.reconstructor = Reconstructor(channels, 3)\n",
        "\n",
        "        # Initialize hidden states\n",
        "        self.hidden_state = None\n",
        "        self.cell_state = None\n",
        "\n",
        "    def init_hidden(self, batch_size, height, width, device):\n",
        "        self.hidden_state = torch.zeros(batch_size, self.channels, height, width, device=device)\n",
        "        self.cell_state = torch.zeros(batch_size, self.channels, height, width, device=device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (B, T, C, H, W) or (B, C, H, W) for single frame\n",
        "        if len(x.shape) == 4:\n",
        "            # Single frame\n",
        "            x = x.unsqueeze(1)  # Add time dimension\n",
        "\n",
        "        B, T, C, H, W = x.shape\n",
        "        device = x.device\n",
        "\n",
        "        # Initialize hidden states if needed\n",
        "        if self.hidden_state is None or self.hidden_state.shape[0] != B:\n",
        "            self.init_hidden(B, H, W, device)\n",
        "\n",
        "        outputs = []\n",
        "\n",
        "        for t in range(T):\n",
        "            frame = x[:, t]  # (B, C, H, W)\n",
        "\n",
        "            # Extract features\n",
        "            features = self.feature_extractor(frame)  # (B, channels, H, W)\n",
        "\n",
        "            # Temporal modeling with ConvLSTM\n",
        "            self.hidden_state, self.cell_state = self.conv_lstm(\n",
        "                features, (self.hidden_state, self.cell_state)\n",
        "            )\n",
        "\n",
        "            # Refine features\n",
        "            refined_features = self.feature_refinement(self.hidden_state)\n",
        "\n",
        "            # Reconstruct frame\n",
        "            output_frame = self.reconstructor(refined_features)\n",
        "\n",
        "            outputs.append(output_frame)\n",
        "\n",
        "        return torch.stack(outputs, dim=1)  # (B, T, C, H, W)\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.hidden_state = None\n",
        "        self.cell_state = None\n",
        "\n",
        "class VideoDeblurrer:\n",
        "    def __init__(self, model_path=None, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "        self.device = device\n",
        "        self.model = RVRT(channels=64).to(device)\n",
        "\n",
        "        if model_path and os.path.exists(model_path):\n",
        "            try:\n",
        "                self.model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "                print(f\"‚úÖ Loaded pre-trained model from {model_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Could not load model: {e}\")\n",
        "                print(\"Using randomly initialized model\")\n",
        "        else:\n",
        "            print(\"üîß Using randomly initialized model (for demonstration)\")\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "    def preprocess_frame(self, frame):\n",
        "        # Convert BGR to RGB and normalize to [-1, 1]\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        frame = frame.astype(np.float32) / 127.5 - 1.0  # Normalize to [-1, 1]\n",
        "        return frame\n",
        "\n",
        "    def postprocess_frame(self, frame):\n",
        "        # Denormalize from [-1, 1] to [0, 255] and convert RGB to BGR\n",
        "        frame = (frame + 1.0) * 127.5\n",
        "        frame = np.clip(frame, 0, 255).astype(np.uint8)\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "        return frame\n",
        "\n",
        "    def deblur_video(self, input_path, output_path, max_frames_per_batch=5):\n",
        "        if not os.path.exists(input_path):\n",
        "            raise FileNotFoundError(f\"Input video not found: {input_path}\")\n",
        "\n",
        "        # Open input video\n",
        "        cap = cv2.VideoCapture(input_path)\n",
        "        if not cap.isOpened():\n",
        "            raise ValueError(f\"Could not open video: {input_path}\")\n",
        "\n",
        "        # Get video properties\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        print(f\"üìπ Video Info: {width}x{height}, {fps} FPS, {total_frames} frames\")\n",
        "\n",
        "        # Setup output video writer\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        frames_buffer = []\n",
        "        processed_count = 0\n",
        "\n",
        "        # Reset model states\n",
        "        self.model.reset_states()\n",
        "\n",
        "        print(\"üöÄ Starting video processing...\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                # Preprocess frame\n",
        "                processed_frame = self.preprocess_frame(frame)\n",
        "                frames_buffer.append(processed_frame)\n",
        "\n",
        "                # Process when buffer is full or at end of video\n",
        "                if len(frames_buffer) == max_frames_per_batch or processed_count + len(frames_buffer) == total_frames:\n",
        "                    try:\n",
        "                        # Convert to tensor (B=1, T, C, H, W)\n",
        "                        batch_frames = np.stack(frames_buffer, axis=0)  # (T, H, W, C)\n",
        "                        batch_frames = torch.from_numpy(batch_frames).permute(0, 3, 1, 2).unsqueeze(0)  # (1, T, C, H, W)\n",
        "                        batch_frames = batch_frames.to(self.device)\n",
        "\n",
        "                        print(f\"Processing batch: {batch_frames.shape}\")\n",
        "\n",
        "                        # Process through model\n",
        "                        deblurred_frames = self.model(batch_frames)  # (1, T, C, H, W)\n",
        "\n",
        "                        # Convert back to numpy\n",
        "                        deblurred_frames = deblurred_frames.squeeze(0).permute(0, 2, 3, 1).cpu().numpy()  # (T, H, W, C)\n",
        "\n",
        "                        # Write frames\n",
        "                        for i in range(len(frames_buffer)):\n",
        "                            output_frame = self.postprocess_frame(deblurred_frames[i])\n",
        "                            out.write(output_frame)\n",
        "                            processed_count += 1\n",
        "\n",
        "                            if processed_count % 30 == 0:\n",
        "                                progress = processed_count / total_frames * 100\n",
        "                                print(f\"üìä Progress: {processed_count}/{total_frames} ({progress:.1f}%)\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"‚ö†Ô∏è Error processing batch: {e}\")\n",
        "                        # Fallback: write original frames\n",
        "                        for frame_data in frames_buffer:\n",
        "                            # Convert back to [0, 255] range\n",
        "                            fallback_frame = (frame_data + 1.0) * 127.5\n",
        "                            fallback_frame = np.clip(fallback_frame, 0, 255).astype(np.uint8)\n",
        "                            fallback_frame = cv2.cvtColor(fallback_frame, cv2.COLOR_RGB2BGR)\n",
        "                            out.write(fallback_frame)\n",
        "                            processed_count += 1\n",
        "\n",
        "                    frames_buffer.clear()\n",
        "\n",
        "        # Cleanup\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        print(f\"‚úÖ Video deblurring completed!\")\n",
        "        print(f\"üìÅ Output saved to: {output_path}\")\n",
        "\n",
        "# Simple function for easy usage\n",
        "def deblur_video_simple(input_path, output_path=None, model_path=None):\n",
        "    \"\"\"\n",
        "    Simple function to deblur a video\n",
        "\n",
        "    Args:\n",
        "        input_path (str): Path to the blurred input video\n",
        "        output_path (str, optional): Path for the deblurred output video\n",
        "        model_path (str, optional): Path to pre-trained model weights\n",
        "    \"\"\"\n",
        "    print(\"üé¨ RVRT Video Deblurring System\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    if not os.path.exists(input_path):\n",
        "        print(f\"‚ùå Error: File not found - {input_path}\")\n",
        "        return False\n",
        "\n",
        "    # Generate output path if not provided\n",
        "    if output_path is None:\n",
        "        input_path_obj = Path(input_path)\n",
        "        output_path = str(input_path_obj.parent / f\"{input_path_obj.stem}_deblurred.mp4\")\n",
        "\n",
        "    print(f\"üìπ Input: {input_path}\")\n",
        "    print(f\"üíæ Output: {output_path}\")\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"üîß Device: {device}\")\n",
        "\n",
        "    # Initialize deblurrer\n",
        "    deblurrer = VideoDeblurrer(model_path=model_path, device=device)\n",
        "\n",
        "    try:\n",
        "        deblurrer.deblur_video(input_path, output_path)\n",
        "        print(f\"\\nüéâ SUCCESS! Deblurred video saved to:\")\n",
        "        print(f\"üìÇ {output_path}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error during processing: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description='RVRT Video Deblurring')\n",
        "    parser.add_argument('--input', type=str, required=True, help='Path to input blurred video')\n",
        "    parser.add_argument('--output', type=str, default=None, help='Path to output deblurred video')\n",
        "    parser.add_argument('--model', type=str, default=None, help='Path to pre-trained model (optional)')\n",
        "    parser.add_argument('--device', type=str, default='auto', choices=['auto', 'cuda', 'cpu'])\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Set device\n",
        "    if args.device == 'auto':\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    else:\n",
        "        device = args.device\n",
        "\n",
        "    # Set output path if not provided\n",
        "    if args.output is None:\n",
        "        input_path = Path(args.input)\n",
        "        args.output = str(input_path.parent / f\"{input_path.stem}_deblurred.mp4\")\n",
        "\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Initialize and run deblurrer\n",
        "    deblurrer = VideoDeblurrer(model_path=args.model, device=device)\n",
        "    deblurrer.deblur_video(args.input, args.output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Check if we're in an interactive environment\n",
        "    try:\n",
        "        get_ipython()\n",
        "        interactive_mode = True\n",
        "    except NameError:\n",
        "        interactive_mode = False\n",
        "\n",
        "    if interactive_mode or len(os.sys.argv) == 1:\n",
        "        # Interactive mode\n",
        "        print(\"üé¨ RVRT Video Deblurring System\")\n",
        "        print(\"=\" * 50)\n",
        "        print(\"üí° Usage: deblur_video_simple('/path/to/video.mp4')\")\n",
        "        print(\"üí° Or enter video path below:\")\n",
        "\n",
        "        try:\n",
        "            input_path = input(\"\\nüìÅ Enter video path: \").strip().strip('\"')\n",
        "            if input_path:\n",
        "                deblur_video_simple(input_path)\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nüëã Goodbye!\")\n",
        "    else:\n",
        "        main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEKZDZA9Wp29",
        "outputId": "c016d033-630f-4af0-91d3-f3418ea7af72"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé¨ RVRT Video Deblurring System\n",
            "==================================================\n",
            "üí° Usage: deblur_video_simple('/path/to/video.mp4')\n",
            "üí° Or enter video path below:\n",
            "\n",
            "üìÅ Enter video path: /content/WhatsApp Video 2025-06-12 at 14.10.17_c5f5aa48.mp4\n",
            "üé¨ RVRT Video Deblurring System\n",
            "==================================================\n",
            "üìπ Input: /content/WhatsApp Video 2025-06-12 at 14.10.17_c5f5aa48.mp4\n",
            "üíæ Output: /content/WhatsApp Video 2025-06-12 at 14.10.17_c5f5aa48_deblurred.mp4\n",
            "üîß Device: cuda\n",
            "üîß Using randomly initialized model (for demonstration)\n",
            "üìπ Video Info: 1920x1080, 25 FPS, 372 frames\n",
            "üöÄ Starting video processing...\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "üìä Progress: 30/372 (8.1%)\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "üìä Progress: 60/372 (16.1%)\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "üìä Progress: 90/372 (24.2%)\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "üìä Progress: 120/372 (32.3%)\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "üìä Progress: 150/372 (40.3%)\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "üìä Progress: 180/372 (48.4%)\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "üìä Progress: 210/372 (56.5%)\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "üìä Progress: 240/372 (64.5%)\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "üìä Progress: 270/372 (72.6%)\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "üìä Progress: 300/372 (80.6%)\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "üìä Progress: 330/372 (88.7%)\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "üìä Progress: 360/372 (96.8%)\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 5, 3, 1080, 1920])\n",
            "Processing batch: torch.Size([1, 2, 3, 1080, 1920])\n",
            "‚úÖ Video deblurring completed!\n",
            "üìÅ Output saved to: /content/WhatsApp Video 2025-06-12 at 14.10.17_c5f5aa48_deblurred.mp4\n",
            "\n",
            "üéâ SUCCESS! Deblurred video saved to:\n",
            "üìÇ /content/WhatsApp Video 2025-06-12 at 14.10.17_c5f5aa48_deblurred.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MviMj3imX-SJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}